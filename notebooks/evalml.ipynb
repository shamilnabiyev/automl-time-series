{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ff4983",
   "metadata": {},
   "source": [
    "# EvalML\n",
    "\n",
    "GitHub: https://github.com/alteryx/evalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6401b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from evalml.automl import AutoMLSearch\n",
    "from evalml.problem_types.problem_types import ProblemTypes\n",
    "from evalml.pipelines import TimeSeriesBinaryClassificationPipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c56e7e",
   "metadata": {},
   "source": [
    "## Generate a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b325055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(\n",
    "    {\"date\": pd.date_range(\"2010-10-01\", periods=500), \n",
    "     \"feature1\": range(101, 601), \n",
    "     # \"feature2\": range(351, 851), \n",
    "     # \"feature3\": range(11, 511),\n",
    "    }\n",
    ")\n",
    "\n",
    "y = (pd.Series([1] * 50 + [0] * 450)\n",
    "     .sample(frac=1, random_state=0, replace=False)\n",
    "     .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "X.ww.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033169d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045391e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b044ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y.index, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 train and test sets\n",
    "sample_size = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X[0:sample_size]\n",
    "y_train = y[0:sample_size]\n",
    "\n",
    "X_test = X[sample_size:]\n",
    "y_test = y[sample_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f4b1b",
   "metadata": {},
   "source": [
    "## Experiment 1: Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components.utils import allowed_model_families\n",
    "# list(map(str, allowed_model_families(\"binary\")))\n",
    "from evalml.model_family import ModelFamily\n",
    "\n",
    "print(allowed_model_families(\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_config = {\n",
    "    \"max_delay\": 10,\n",
    "    \"gap\": 0,\n",
    "    \"forecast_horizon\": 1,\n",
    "    \"time_index\": \"date\",\n",
    "}\n",
    "\n",
    "# model_families=[ModelFamily.XGBOOST, ModelFamily.LIGHTGBM, ModelFamily.CATBOOST]\n",
    "model_families=[ModelFamily.CATBOOST]\n",
    "\n",
    "automl = AutoMLSearch(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    problem_type=ProblemTypes.TIME_SERIES_BINARY,\n",
    "    problem_configuration=problem_config,\n",
    "    max_time=60*10, # Limit the pipeline search to 10 minutes\n",
    "    allowed_model_families=model_families,\n",
    "    objective='f1',\n",
    "    sampler_method=None, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb98723",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "automl.search()\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.objectives import get_all_objective_names\n",
    "print(get_all_objective_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95762a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = automl.best_pipeline\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "best_pipeline_score = pl.score(X_test, y_test, ['f1'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083357d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee8b28",
   "metadata": {},
   "source": [
    "## Experiment 2: Human Activity Recognition - HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source: https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones\n",
    "train = pd.read_csv(\"../data/human-activity-recognition/train.csv\")\n",
    "\n",
    "# Convert labels to binary\n",
    "train['Activity'] = pd.DataFrame(np.where(train['Activity']=='WALKING_DOWNSTAIRS', 1, 0))\n",
    "\n",
    "# Create a new date column\n",
    "train['date'] = pd.date_range(start='1/1/2022', periods=len(train), freq='S')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e19cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The max value will be incremented by 1 second and used in test dataset (see below)\n",
    "train['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[train.columns.difference(['subject', 'Activity'])]\n",
    "X.ww.init()\n",
    "\n",
    "X_train = X[0:800]\n",
    "X_val = X[800:200]\n",
    "\n",
    "y_train = train['Activity'][0:800]\n",
    "y_val = train['Activity'][800:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6846cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train)\n",
    "plt.title('Histogram of activites')\n",
    "plt.xticks(rotation = 90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.demos import load_weather\n",
    "from evalml.automl import AutoMLSearch\n",
    "from evalml.utils.gen_utils import validate_holdout_datasets\n",
    "from evalml.problem_types.problem_types import ProblemTypes\n",
    "import woodwork as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a69228",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_config = {'gap': 0, \n",
    "                  'max_delay': 10, \n",
    "                  'forecast_horizon': 1, \n",
    "                  'time_index': 'date'\n",
    "                 }\n",
    "\n",
    "# model_families=['xgboost', 'random_forest', 'linear_model', 'extra_trees','decision_tree']\n",
    "# model_families=[ModelFamily.XGBOOST, ModelFamily.LIGHTGBM, ModelFamily.CATBOOST]\n",
    "model_families=[ModelFamily.XGBOOST]\n",
    "\n",
    "automl = AutoMLSearch(X_train, \n",
    "                      y_train, \n",
    "                      problem_type=ProblemTypes.TIME_SERIES_BINARY,\n",
    "                      max_batches=1,\n",
    "                      problem_configuration=problem_config,\n",
    "                      max_time=60*10, # limit the pipeline search duration\n",
    "                      allowed_model_families=model_families,\n",
    "                      objective='f1',\n",
    "                      sampler_method=None, \n",
    "                      verbose=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be83872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "automl.search()\n",
    "\n",
    "print('') # Started at 13:23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/human-activity-recognition/test.csv\")\n",
    "test['Activity'] = pd.DataFrame(np.where(test['Activity']=='WALKING_DOWNSTAIRS', 1, 0))\n",
    "test['date'] = pd.date_range(start='1/1/2022 02:02:32', periods=len(test), freq='S')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 562 features. Ignore the 'subject' column\n",
    "X_test = test[test.columns.difference(['subject', 'Activity'])]\n",
    "# X_test['date'] = pd.date_range(start='1/1/2022 02:02:32', periods=len(X_test), freq='S')\n",
    "# Select the 'activity' column as an outcome\n",
    "y_test = test['Activity'] #.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = automl.best_pipeline\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "best_pipeline_score = pl.score(X_test, y_test, ['f1'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183e1b7",
   "metadata": {},
   "source": [
    "TODO: try to debug the code and find out the reason of the following exception:\n",
    "\n",
    "\n",
    "```\n",
    "PipelineScoreError: F1 encountered AttributeError with message ('NoneType' object has no attribute 'iloc'):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858263b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsc_pipeline = TimeSeriesBinaryClassificationPipeline(\n",
    "    # component_graph=[], \n",
    "    component_graph = ['Logistic Regression Classifier'],\n",
    "    parameters={\"pipeline\": {\"gap\": 0, \"max_delay\": 1, \"forecast_horizon\": 1, \"time_index\": \"date\"}}, \n",
    "    custom_name=None, \n",
    "    random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7df81",
   "metadata": {},
   "source": [
    "**ValueError**: no such file ../automl-time-series/venv/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325bc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "races =   [\"asian\",\"black\",\"hispanic\",\"other\",\"white\"]\n",
    "\n",
    "# Generate random data\n",
    "voter_race = np.random.choice(a= races,\n",
    "                              p = [0.05, 0.15 ,0.25, 0.05, 0.5],\n",
    "                              size=1000)\n",
    "\n",
    "voter_age = stats.poisson.rvs(loc=18,\n",
    "                              mu=30,\n",
    "                              size=1000)\n",
    "\n",
    "# Group age data by race\n",
    "voter_frame = pd.DataFrame({\"race\":voter_race,\"age\":voter_age})\n",
    "groups = voter_frame.groupby(\"race\").groups\n",
    "\n",
    "# Etract individual groups\n",
    "asian = voter_age[groups[\"asian\"]]\n",
    "black = voter_age[groups[\"black\"]]\n",
    "hispanic = voter_age[groups[\"hispanic\"]]\n",
    "other = voter_age[groups[\"other\"]]\n",
    "white = voter_age[groups[\"white\"]]\n",
    "\n",
    "# Perform the ANOVA\n",
    "stats.f_oneway(asian, black, hispanic, other, white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec651d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(asian),\\\n",
    "np.mean(black),\\\n",
    "np.mean(hispanic),\\\n",
    "np.mean(other),\\\n",
    "np.mean(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "# Generate random data\n",
    "voter_race = np.random.choice(a= races,\n",
    "                              p = [0.05, 0.15 ,0.25, 0.05, 0.5],\n",
    "                              size=1000)\n",
    "\n",
    "# Use a different distribution for white ages\n",
    "white_ages = stats.poisson.rvs(loc=18, \n",
    "                              mu=32,\n",
    "                              size=1000)\n",
    "\n",
    "voter_age = stats.poisson.rvs(loc=18,\n",
    "                              mu=30,\n",
    "                              size=1000)\n",
    "\n",
    "voter_age = np.where(voter_race==\"white\", white_ages, voter_age)\n",
    "\n",
    "# Group age data by race\n",
    "voter_frame = pd.DataFrame({\"race\":voter_race,\"age\":voter_age})\n",
    "groups = voter_frame.groupby(\"race\").groups   \n",
    "\n",
    "# Extract individual groups\n",
    "asian = voter_age[groups[\"asian\"]]\n",
    "black = voter_age[groups[\"black\"]]\n",
    "hispanic = voter_age[groups[\"hispanic\"]]\n",
    "other = voter_age[groups[\"other\"]]\n",
    "white = voter_age[groups[\"white\"]]\n",
    "\n",
    "# Perform the ANOVA\n",
    "stats.f_oneway(asian, black, hispanic, other, white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(asian),\\\n",
    "np.mean(black),\\\n",
    "np.mean(hispanic),\\\n",
    "np.mean(other),\\\n",
    "np.mean(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0741b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_ages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
