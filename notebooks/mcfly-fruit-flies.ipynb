{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c27ad72",
   "metadata": {},
   "source": [
    "# Mcfly using tensorflow.data.Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf6798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from sktime.datatypes import convert_to\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.datasets import load_from_arff_to_dataframe\n",
    "from mcfly.find_architecture import find_best_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2f4f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f56c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0       0.000244\n",
       "1       0.001831\n",
       "2      -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      -0.000244\n",
       "1       0.000275\n",
       "2      -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0       0.002350\n",
       "1      -0.002441\n",
       "2      -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0       0.001465\n",
       "1       0.001221\n",
       "2      -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0       0.000397\n",
       "1      -0.000061\n",
       "2      -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dim_0\n",
       "0  0       0.000244\n",
       "1       0.001831\n",
       "2      -0.00...\n",
       "1  0      -0.000244\n",
       "1       0.000275\n",
       "2      -0.00...\n",
       "2  0       0.002350\n",
       "1      -0.002441\n",
       "2      -0.00...\n",
       "3  0       0.001465\n",
       "1       0.001221\n",
       "2      -0.00...\n",
       "4  0       0.000397\n",
       "1      -0.000061\n",
       "2      -0.00..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/NABS/Downloads/FruitFlies/\"\n",
    "X, y = load_from_arff_to_dataframe(\n",
    "    os.path.join(DATA_PATH, \"FruitFlies_TRAIN.arff\")\n",
    ")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d454548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['melanogaster', 'melanogaster', 'melanogaster', ..., 'zaprionus',\n",
       "       'zaprionus', 'zaprionus'], dtype='<U12')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d6882eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['melanogaster', 'suzukii', 'zaprionus'], dtype='<U12')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe3d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17259, 1, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np = convert_to(X, to_type=\"numpy3D\")\n",
    "X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2663e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17259, 5000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np = np.swapaxes(X_np, 1, 2)\n",
    "X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c3171b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.38 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(X_np.shape[0]):\n",
    "    with open(os.path.join(DATA_PATH, \"instances\", f\"instance_{i}_label_{y[i]}_.npy\"), 'wb') as f:\n",
    "        np.save(f, X_np[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "01698932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np[0, np.newaxis, :, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8aad4",
   "metadata": {},
   "source": [
    "## tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7ddd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zaprionus', 'suzukii', 'suzukii', 'suzukii', 'zaprionus']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/NABS/Downloads/FruitFlies/\"\n",
    "\n",
    "file_names = os.listdir(os.path.join(DATA_PATH, \"instances\"))\n",
    "random.shuffle(file_names)\n",
    "\n",
    "labels = map(lambda x: x.split(\"_\")[3], file_names)\n",
    "labels = list(labels)\n",
    "\n",
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308d1240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['instance_15155_label_zaprionus_.npy', 'instance_7185_label_suzukii_.npy'],\n",
       " ['zaprionus', 'suzukii'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names[0:2], labels[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b73016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, train_label, val_label = train_test_split(\n",
    "    file_names, \n",
    "    labels, \n",
    "    train_size=0.80, \n",
    "    random_state=42, \n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2acc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set = set(labels)\n",
    "labels_int = list(range(len(labels_set)))\n",
    "labels_dict = dict(zip(labels_set, labels_int))\n",
    "NUM_CLASSES = len(labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9df0e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_generator(data_set):\n",
    "    def get_int_label(file_name):\n",
    "        string_label = file_name.split(\"_\")[3]\n",
    "        return labels_dict[string_label]\n",
    "    \n",
    "    def get_x_y(file_name):\n",
    "        x = np.load(os.path.join(DATA_PATH, \"instances\", file_name))\n",
    "        y = get_int_label(file_name)\n",
    "        y = tf.constant(y)\n",
    "        y = tf.one_hot(y, NUM_CLASSES)\n",
    "        return x, y\n",
    "    \n",
    "    def func(i):\n",
    "        idx = i.numpy() # Decoding from the EagerTensor object\n",
    "        x, y = get_x_y(data_set[idx])\n",
    "        return x, y\n",
    "\n",
    "    z = list(range(len(data_set)))\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: z, tf.uint16)\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=len(z), seed=0,  \n",
    "                              reshuffle_each_iteration=True)\n",
    "    dataset = dataset.map(lambda i: tf.py_function(func=func, \n",
    "                                                   inp=[i], \n",
    "                                                   Tout=[tf.float32,\n",
    "                                                         tf.float32]\n",
    "                                                   ), \n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(8)#.map(_fixup_shape)\n",
    "    # dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_generator = get_dataset_generator(train_set)\n",
    "val_generator = get_dataset_generator(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88de59fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5000, 1) tf.Tensor(\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]], shape=(8, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x_tmp, y_tmp in val_generator.take(1):\n",
    "    print(x_tmp.shape, y_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778e498",
   "metadata": {},
   "source": [
    "## Keras data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddada66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suzukii': 0, 'melanogaster': 1, 'zaprionus': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7a3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = {}\n",
    "for file_name in train_set:\n",
    "    lab = file_name.split(\"_\")[3]\n",
    "    lab = labels_dict[lab]\n",
    "    new_labels[file_name] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "05e3429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1, 5000, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((8, *(1, 5000), 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b912380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=5000, n_channels=1,\n",
    "                 n_classes=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            DATA_PATH = \"C:/Users/NABS/Downloads/FruitFlies/\"\n",
    "            X[i, ] = np.load(os.path.join(DATA_PATH, \"instances\", ID))\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e24ff77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtmp = np.empty((8, 5000, 1))\n",
    "Xtmp[0, ] = np.load(os.path.join(DATA_PATH, \"instances\", 'instance_13556_label_zaprionus_.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "59c72542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5000, 1)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "768f4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'dim': 5000,\n",
    "          'batch_size': 3,\n",
    "          'n_classes': 3,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_set, new_labels, **params)\n",
    "validation_generator = DataGenerator(val_set, new_labels, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcde1f8",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1f6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcfly.modelgen import generate_models\n",
    "from mcfly.find_architecture import train_models_on_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f644a846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NABS\\Documents\\GitProjects\\automl-time-series\\venv\\lib\\site-packages\\mcfly\\modelgen.py:86: UserWarning: Specified number_of_models is smaller than the given number of model types.\n",
      "  warnings.warn(\"Specified number_of_models is smaller than the given number of model types.\")\n",
      "C:\\Users\\NABS\\Documents\\GitProjects\\automl-time-series\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "models = generate_models(x_shape=(None, 5000, 1), \n",
    "                         number_of_classes=3,\n",
    "                         number_of_models=2,\n",
    "                         metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f228f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<keras.engine.functional.Functional at 0x13db763f310>,\n",
       "  {'learning_rate': 0.006191830789697886,\n",
       "   'regularization_rate': 0.02271788149250915,\n",
       "   'network_depth': 4,\n",
       "   'filters_number': 63,\n",
       "   'max_kernel_size': 90},\n",
       "  'InceptionTime'),\n",
       " (<keras.engine.functional.Functional at 0x13dbf051b50>,\n",
       "  {'learning_rate': 0.006649371027656127,\n",
       "   'regularization_rate': 0.00016364120810765338,\n",
       "   'network_depth': 5,\n",
       "   'min_filters_number': 92,\n",
       "   'max_kernel_size': 28},\n",
       "  'ResNet')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca1de07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m histories, val_accuracies, val_losses \u001b[38;5;241m=\u001b[39m\\\n\u001b[1;32m----> 2\u001b[0m     train_models_on_samples(\u001b[43mtraining_generator\u001b[49m,\n\u001b[0;32m      3\u001b[0m                             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m                             validation_generator,\n\u001b[0;32m      5\u001b[0m                             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m                             models,\n\u001b[0;32m      7\u001b[0m                             \u001b[38;5;66;03m# batch_size=5,\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                             \u001b[38;5;66;03m#nr_epochs=20,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                             \u001b[38;5;66;03m#subset_size=1000,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                             \u001b[38;5;66;03m#outputfile=outputfile,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m                             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "histories, val_accuracies, val_losses =\\\n",
    "    train_models_on_samples(training_generator,\n",
    "                            None,\n",
    "                            validation_generator,\n",
    "                            None,\n",
    "                            models,\n",
    "                            # batch_size=5,\n",
    "                            #nr_epochs=20,\n",
    "                            #subset_size=1000,\n",
    "                            verbose=True,\n",
    "                            #outputfile=outputfile,\n",
    "                            metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_params, best_model_type, knn_acc = \\\n",
    "            find_best_architecture(\n",
    "                X_train=training_generator,\n",
    "                y_train=None,\n",
    "                X_val=validation_generator,\n",
    "                y_val=None, \n",
    "                number_of_models=5,\n",
    "                nr_epochs=20\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1535192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
